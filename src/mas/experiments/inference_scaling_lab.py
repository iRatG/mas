#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞ –¥–ª—è MAS —Å–∏—Å—Ç–µ–º—ã.
–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–∫–∞–Ω–¥–∏–¥–∞—Ç—ã, —Ä–µ–≤—å—é–µ—Ä—ã, —Ä–µ—Ç—Ä–∞–∏) –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
"""

from __future__ import annotations
import csv
import json
import subprocess
import sys
import time
from itertools import product
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple
import statistics

PY = sys.executable
ROOT = Path(__file__).resolve().parent

def run_experiment(approach: str, seed: int, n_candidates: int, n_reviewers: int, max_retries: int, cases: List[int] = None) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞—é—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ/–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞.
    –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π JSON.
    """
    if cases is None:
        cases = [1, 2, 3, 4, 5]
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
    cmd = [
        PY, str(ROOT / "main.py"),
        "--approach", approach,
        "--seed", str(seed),
        "--n-candidates", str(n_candidates),
        "--n-reviewers", str(n_reviewers), 
        "--max-retries", str(max_retries),
        "--cases"
    ] + [str(c) for c in cases]
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    temp_results = ROOT / f"temp_results_{approach}_{int(time.time()*1000)}.json"
    cmd.extend(["--save-results", str(temp_results)])
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        execution_time = time.time() - start_time
        
        # –ß–∏—Ç–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        detailed_results = {}
        if temp_results.exists():
            try:
                detailed_results = json.loads(temp_results.read_text(encoding='utf-8'))
                temp_results.unlink()  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            except Exception:
                pass
        
        # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –≤—ã–≤–æ–¥–∞
        metrics = parse_output(result.stdout)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        experiment_result = {
            'approach': approach,
            'n_candidates': n_candidates,
            'n_reviewers': n_reviewers,
            'max_retries': max_retries,
            'seed': seed,
            'cases_tested': cases,
            'execution_time': round(execution_time, 3),
            'return_code': result.returncode,
            **metrics
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if detailed_results:
            experiment_result['detailed_metrics'] = detailed_results
            
        return experiment_result
        
    except subprocess.TimeoutExpired:
        return {
            'approach': approach,
            'n_candidates': n_candidates,
            'n_reviewers': n_reviewers,
            'max_retries': max_retries,
            'seed': seed,
            'cases_tested': cases,
            'execution_time': 60.0,
            'return_code': -1,
            'error': 'TIMEOUT',
            'success_count': 0,
            'fail_count': len(cases)
        }
    except Exception as e:
        return {
            'approach': approach,
            'n_candidates': n_candidates,
            'n_reviewers': n_reviewers,
            'max_retries': max_retries,
            'seed': seed,
            'cases_tested': cases,
            'execution_time': 0.0,
            'return_code': -2,
            'error': str(e),
            'success_count': 0,
            'fail_count': len(cases)
        }
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if temp_results.exists():
            temp_results.unlink()

def parse_output(stdout: str) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏—Ç stdout main.py –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—É—Å–ø–µ—Ö/–≤—Ä–µ–º—è)."""
    lines = stdout.splitlines()
    metrics = {
        'success_count': 0,
        'fail_count': 0,
        'timeout_count': 0,
        'avg_execution_time': None,
        'total_candidates': None,
        'total_reviews': None,
        'success_rate': None
    }
    
    execution_times = []
    
    for line in lines:
        line = line.strip()
        
        # –ü–æ–¥—Å—á—ë—Ç —É—Å–ø–µ—à–Ω—ã—Ö/–Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤
        if "‚úÖ –°—Ç–∞—Ç—É—Å: success" in line:
            metrics['success_count'] += 1
        elif "‚ùå –°—Ç–∞—Ç—É—Å: failed" in line:
            metrics['fail_count'] += 1
        elif "‚è∞ –°—Ç–∞—Ç—É—Å: timeout" in line:
            metrics['timeout_count'] += 1
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if "–í—Ä–µ–º—è:" in line:
            try:
                time_str = line.split("–í—Ä–µ–º—è:")[1].split("—Å–µ–∫")[0].strip()
                execution_times.append(float(time_str))
            except (ValueError, IndexError):
                pass
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏–∑ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞
        if "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:" in line:
            try:
                time_str = line.split("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:")[1].split("—Å–µ–∫")[0].strip()
                metrics['avg_execution_time'] = float(time_str)
            except (ValueError, IndexError):
                pass
        
        if "–°—Ä–µ–¥–Ω–µ–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –∫–µ–π—Å:" in line:
            try:
                candidates_str = line.split("–°—Ä–µ–¥–Ω–µ–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –∫–µ–π—Å:")[1].strip()
                metrics['total_candidates'] = float(candidates_str)
            except (ValueError, IndexError):
                pass
    
    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if execution_times:
        metrics['avg_execution_time'] = round(statistics.mean(execution_times), 4)
        metrics['min_execution_time'] = round(min(execution_times), 4)
        metrics['max_execution_time'] = round(max(execution_times), 4)
    
    total_cases = metrics['success_count'] + metrics['fail_count'] + metrics['timeout_count']
    if total_cases > 0:
        metrics['success_rate'] = round(metrics['success_count'] / total_cases, 3)
    
    return metrics

def run_scaling_experiment() -> List[Dict[str, Any]]:
    """–ì–æ–Ω—è–µ—Ç —Å–µ—Ç–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤."""
    print("üî¨ –ó–∞–ø—É—Å–∫ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞...")
    print("="*60)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    approaches = ["sync", "async"]
    candidates_grid = [1, 2, 3, 5]
    reviewers_grid = [1, 3, 5]
    retries_grid = [0, 1, 2]
    seed = 42
    
    # –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–µ–π—Å–æ–≤
    test_cases = [1, 2, 3]  # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–æ [1, 2, 3, 4, 5] –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
    
    results = []
    total_experiments = len(approaches) * len(candidates_grid) * len(reviewers_grid) * len(retries_grid)
    
    print(f"–í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {total_experiments}")
    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∫–µ–π—Å—ã: {test_cases}")
    print(f"–ü–æ–¥—Ö–æ–¥—ã: {approaches}")
    print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç—ã: {candidates_grid}")
    print(f"–†–µ–≤—å—é–µ—Ä—ã: {reviewers_grid}")
    print(f"–†–µ—Ç—Ä–∞–∏: {retries_grid}")
    print()
    
    experiment_num = 0
    
    for approach in approaches:
        for n_cand, n_rev, n_ret in product(candidates_grid, reviewers_grid, retries_grid):
            experiment_num += 1
            
            print(f"[{experiment_num}/{total_experiments}] {approach} | "
                  f"–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤={n_cand}, —Ä–µ–≤—å—é–µ—Ä–æ–≤={n_rev}, —Ä–µ—Ç—Ä–∞–µ–≤={n_ret}")
            
            result = run_experiment(approach, seed, n_cand, n_rev, n_ret, test_cases)
            results.append(result)
            
            # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            status = "‚úÖ" if result.get('success_count', 0) == len(test_cases) else "‚ùå"
            exec_time = result.get('execution_time', 0)
            success_rate = result.get('success_rate', 0) or 0
            
            print(f"   {status} –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1%}, –í—Ä–µ–º—è: {exec_time:.3f}—Å")
    
    return results

def analyze_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–¥—Ö–æ–¥–∞–º."""
    analysis = {
        'total_experiments': len(results),
        'by_approach': {},
        'best_configurations': {},
        'parameter_impact': {}
    }
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ–¥—Ö–æ–¥–∞–º
    sync_results = [r for r in results if r['approach'] == 'sync']
    async_results = [r for r in results if r['approach'] == 'async']
    
    for approach_name, approach_results in [('sync', sync_results), ('async', async_results)]:
        if not approach_results:
            continue
        
        success_rates = [(r.get('success_rate') or 0) for r in approach_results]
        exec_times = [float(r.get('execution_time', 0) or 0) for r in approach_results]
        sr_clean = [float(x) for x in success_rates if isinstance(x, (int, float))]
        et_clean = [float(x) for x in exec_times if isinstance(x, (int, float))]
        
        analysis['by_approach'][approach_name] = {
            'experiments_count': len(approach_results),
            'avg_success_rate': round(statistics.mean(sr_clean), 3) if sr_clean else 0.0,
            'best_success_rate': max(sr_clean) if sr_clean else 0.0,
            'avg_execution_time': round(statistics.mean(et_clean), 3) if et_clean else 0.0,
            'fastest_time': min(et_clean) if et_clean else 0.0
        }
    
    # –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    best_overall = max(results, key=lambda r: ((r.get('success_rate') or 0), -(r.get('execution_time') or float('inf'))))
    fastest_successful = min([r for r in results if r.get('success_rate', 0) == 1.0], 
                           key=lambda r: r.get('execution_time', float('inf')), default=None)
    
    analysis['best_configurations'] = {
        'overall_best': {
            'approach': best_overall['approach'],
            'n_candidates': best_overall['n_candidates'],
            'n_reviewers': best_overall['n_reviewers'],
            'max_retries': best_overall['max_retries'],
            'success_rate': best_overall.get('success_rate', 0),
            'execution_time': best_overall.get('execution_time', 0)
        }
    }
    
    if fastest_successful:
        analysis['best_configurations']['fastest_perfect'] = {
            'approach': fastest_successful['approach'],
            'n_candidates': fastest_successful['n_candidates'],
            'n_reviewers': fastest_successful['n_reviewers'],
            'max_retries': fastest_successful['max_retries'],
            'execution_time': fastest_successful.get('execution_time', 0)
        }
    
    return analysis

def save_results(results: List[Dict[str, Any]], analysis: Dict[str, Any]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑ –≤ CSV –∏ JSON —Ñ–∞–π–ª—ã."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # CSV —Ñ–∞–π–ª –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    csv_file = ROOT / f"inference_scaling_results_{timestamp}.csv"
    if results:
        with csv_file.open('w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
    
    # JSON —Ñ–∞–π–ª —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –∞–Ω–∞–ª–∏–∑–æ–º
    json_file = ROOT / f"inference_scaling_analysis_{timestamp}.json"
    full_data = {
        'metadata': {
            'timestamp': timestamp,
            'total_experiments': len(results),
            'description': '–ò–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –¥–ª—è MAS —Å–∏—Å—Ç–µ–º—ã'
        },
        'results': results,
        'analysis': analysis
    }
    
    json_file.write_text(json.dumps(full_data, ensure_ascii=False, indent=2), encoding='utf-8')
    
    return csv_file, json_file

def print_summary(analysis: Dict[str, Any]):
    """–ö—Ä–∞—Å–∏–≤–æ –ø–µ—á–∞—Ç–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å."""
    print("\n" + "="*60)
    print("üìä –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–ù–§–ï–†–ï–ù–°-–°–ö–ï–ô–õ–ò–ù–ì–ê")
    print("="*60)
    
    print(f"–í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {analysis['total_experiments']}")
    
    for approach, data in analysis['by_approach'].items():
        print(f"\nüîß {approach.upper()} –ø–æ–¥—Ö–æ–¥:")
        print(f"  ‚Ä¢ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {data['experiments_count']}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {data['avg_success_rate']:.1%}")
        print(f"  ‚Ä¢ –õ—É—á—à–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {data['best_success_rate']:.1%}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {data['avg_execution_time']:.3f}—Å")
        print(f"  ‚Ä¢ –õ—É—á—à–µ–µ –≤—Ä–µ–º—è: {data['fastest_time']:.3f}—Å")
    
    print(f"\nüèÜ –õ–£–ß–®–ò–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò:")
    
    best = analysis['best_configurations']['overall_best']
    best_sr = float(best.get('success_rate') or 0.0)
    best_time = float(best.get('execution_time') or 0.0)
    print(f"  ‚Ä¢ –õ—É—á—à–∞—è –æ–±—â–∞—è: {best['approach']} "
          f"(–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤={best['n_candidates']}, —Ä–µ–≤—å—é–µ—Ä–æ–≤={best['n_reviewers']}, —Ä–µ—Ç—Ä–∞–µ–≤={best['max_retries']})")
    print(f"    –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {best_sr:.1%}, –í—Ä–µ–º—è: {best_time:.3f}—Å")
    
    if 'fastest_perfect' in analysis['best_configurations']:
        fastest = analysis['best_configurations']['fastest_perfect']
        print(f"  ‚Ä¢ –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è (100%): {fastest['approach']} "
              f"(–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤={fastest['n_candidates']}, —Ä–µ–≤—å—é–µ—Ä–æ–≤={fastest['n_reviewers']}, —Ä–µ—Ç—Ä–∞–µ–≤={fastest['max_retries']})")
        fastest_time = float(fastest.get('execution_time') or 0.0)
        print(f"    –í—Ä–µ–º—è: {fastest_time:.3f}—Å")

def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞.
    """
    print("üß™ –õ–ê–ë–û–†–ê–¢–û–†–ò–Ø –ò–ù–§–ï–†–ï–ù–°-–°–ö–ï–ô–õ–ò–ù–ì–ê MAS –°–ò–°–¢–ï–ú–´")
    print("–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print()
    
    # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    results = run_scaling_experiment()
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    analysis = analyze_results(results)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    csv_file, json_file = save_results(results, analysis)
    
    # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏
    print_summary(analysis)
    
    print(f"\nüìÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´:")
    print(f"  ‚Ä¢ CSV —Ç–∞–±–ª–∏—Ü–∞: {csv_file}")
    print(f"  ‚Ä¢ JSON –∞–Ω–∞–ª–∏–∑: {json_file}")
    print("\n‚úÖ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()
