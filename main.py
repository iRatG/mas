#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MAS Demo: –≥–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–¥—Ö–æ–¥–æ–≤.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —à–∏–Ω—É –¥–ª—è –∞–≤—Ç–æ-–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–æ–≤.
"""

import argparse
import asyncio
import json
import logging
import time
from typing import Any, Dict, List

from test_cases import BUG_CASES
from approach1_sync import create_sync_orchestrator
from approach2_async import create_async_system, make_cid
from real_llm import is_openai_available

# ----------------------------- –õ–û–ì–ò ---------------------------------

def setup_logging(verbose: bool):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
        datefmt="%H:%M:%S",
    )

log = logging.getLogger("MAS")

# ------------------------- –ê–ù–ê–õ–ò–¢–ò–ö–ê --------------------------------

class OverallAnalytics:
    """–°–∏—Å—Ç–µ–º–∞ –æ–±—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–¥—Ö–æ–¥–æ–≤."""
    
    def __init__(self):
        self.results: List[Dict[str, Any]] = []
        self.start_time = time.time()
        self.llm_mode = "simulation"  # "simulation" –∏–ª–∏ "openai"
        self.openai_model = None
    
    def add_result(self, result: Dict[str, Any]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è."""
        self.results.append(result)
    
    def generate_summary(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞."""
        total_time = time.time() - self.start_time
        
        sync_results = [r for r in self.results if r.get("approach") == "sync"]
        async_results = [r for r in self.results if r.get("approach") == "async"]
        
        summary = {
            "total_execution_time": round(total_time, 3),
            "total_cases": len(self.results),
            "llm_mode": self.llm_mode,
            "openai_model": self.openai_model,
            "sync_approach": self._analyze_approach(sync_results, "sync"),
            "async_approach": self._analyze_approach(async_results, "async"),
            "comparison": self._compare_approaches(sync_results, async_results)
        }
        
        return summary
    
    def _analyze_approach(self, results: List[Dict[str, Any]], approach_name: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞."""
        if not results:
            return {"cases_processed": 0, "success_rate": 0, "average_time": 0}
        
        successful = [r for r in results if r.get("status") == "success"]
        failed = [r for r in results if r.get("status") == "failed"]
        timeouts = [r for r in results if r.get("status") == "timeout"]
        
        metrics = [r.get("metrics", {}) for r in results if "metrics" in r]
        
        analysis = {
            "cases_processed": len(results),
            "successful": len(successful),
            "failed": len(failed),
            "timeouts": len(timeouts),
            "success_rate": round(len(successful) / len(results), 2) if results else 0,
            "average_execution_time": round(
                sum(m.get("execution_time_seconds", 0) for m in metrics) / len(metrics), 3
            ) if metrics else 0,
        }
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        if approach_name == "sync":
            analysis.update({
                "total_retries": sum(m.get("retries_used", 0) for m in metrics),
                "average_candidates_per_case": round(
                    sum(m.get("total_candidates_generated", 0) for m in metrics) / len(metrics), 1
                ) if metrics else 0,
                "average_reviews_per_case": round(
                    sum(m.get("total_reviews_performed", 0) for m in metrics) / len(metrics), 1
                ) if metrics else 0,
            })
        elif approach_name == "async":
            analysis.update({
                "total_messages": sum(m.get("messages_sent", 0) for m in metrics),
                "total_timeouts": sum(m.get("timeouts_occurred", 0) for m in metrics),
                "average_message_efficiency": round(
                    sum(m.get("message_efficiency", 0) for m in metrics) / len(metrics), 2
                ) if metrics else 0,
            })
        
        return analysis
    
    def _compare_approaches(self, sync_results: List[Dict], async_results: List[Dict]) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤."""
        if not sync_results or not async_results:
            return {"comparison_available": False}
        
        sync_metrics = [r.get("metrics", {}) for r in sync_results if "metrics" in r]
        async_metrics = [r.get("metrics", {}) for r in async_results if "metrics" in r]
        
        sync_avg_time = sum(m.get("execution_time_seconds", 0) for m in sync_metrics) / len(sync_metrics)
        async_avg_time = sum(m.get("execution_time_seconds", 0) for m in async_metrics) / len(async_metrics)
        
        sync_success = len([r for r in sync_results if r.get("status") == "success"])
        async_success = len([r for r in async_results if r.get("status") == "success"])
        
        return {
            "comparison_available": True,
            "faster_approach": "sync" if sync_avg_time < async_avg_time else "async",
            "time_difference_seconds": round(abs(sync_avg_time - async_avg_time), 3),
            "more_successful": "sync" if sync_success > async_success else "async" if async_success > sync_success else "equal",
            "success_difference": abs(sync_success - async_success),
        }
    
    def print_summary(self):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å."""
        summary = self.generate_summary()
        
        print("\n" + "="*80)
        print("–°–í–û–î–ù–´–ô –û–¢–ß–Å–¢ –ü–û –ê–ù–ê–õ–ò–ó–£ –ü–û–î–•–û–î–û–í")
        print("="*80)
        
        print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['total_execution_time']} —Å–µ–∫")
        print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–µ–π—Å–æ–≤: {summary['total_cases']}")
        
        print(f"\nüìä –°–ò–ù–•–†–û–ù–ù–´–ô –ü–û–î–•–û–î:")
        sync = summary['sync_approach']
        if sync['cases_processed'] > 0:
            print(f"  ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–µ–π—Å–æ–≤: {sync['cases_processed']}")
            print(f"  ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {sync['successful']}, –ù–µ—É–¥–∞—á–Ω—ã—Ö: {sync['failed']}")
            print(f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {sync['success_rate']*100}%")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {sync['average_execution_time']} —Å–µ–∫")
            print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Ä–µ—Ç—Ä–∞–µ–≤: {sync.get('total_retries', 0)}")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –∫–µ–π—Å: {sync.get('average_candidates_per_case', 0)}")
        else:
            print("  ‚Ä¢ –ù–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è")
        
        print(f"\nüöÄ –ê–°–ò–ù–•–†–û–ù–ù–´–ô –ü–û–î–•–û–î:")
        async_data = summary['async_approach']
        if async_data['cases_processed'] > 0:
            print(f"  ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–µ–π—Å–æ–≤: {async_data['cases_processed']}")
            print(f"  ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {async_data['successful']}, –ù–µ—É–¥–∞—á–Ω—ã—Ö: {async_data['failed']}, –¢–∞–π–º–∞—É—Ç–æ–≤: {async_data['timeouts']}")
            print(f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {async_data['success_rate']*100}%")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {async_data['average_execution_time']} —Å–µ–∫")
            print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {async_data.get('total_messages', 0)}")
            print(f"  ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π: {async_data.get('average_message_efficiency', 0)}")
        else:
            print("  ‚Ä¢ –ù–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è")
        
        comparison = summary['comparison']
        if comparison['comparison_available']:
            print(f"\n‚ö° –°–†–ê–í–ù–ï–ù–ò–ï:")
            print(f"  ‚Ä¢ –ë—ã—Å—Ç—Ä–µ–µ: {comparison['faster_approach']} –ø–æ–¥—Ö–æ–¥")
            print(f"  ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏: {comparison['time_difference_seconds']} —Å–µ–∫")
            print(f"  ‚Ä¢ –ë–æ–ª—å—à–µ —É—Å–ø–µ—à–Ω—ã—Ö: {comparison['more_successful']}")
            print(f"  ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞ –≤ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: {comparison['success_difference']} –∫–µ–π—Å–æ–≤")
        
        print("="*80)

# ------------------------ –ó–ê–ü–£–°–ö –ü–û–î–•–û–î–û–í ---------------------------

async def run_sync_approach(cases: List[Dict[str, Any]], seed: int, analytics: OverallAnalytics, args):
    """–ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞."""
    print(f"\nüîÑ –ó–∞–ø—É—Å–∫ –°–ò–ù–•–†–û–ù–ù–û–ì–û –ø–æ–¥—Ö–æ–¥–∞ (seed={seed})")
    print("-" * 50)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
    kwargs = {'seed': seed}
    if args.n_candidates:
        kwargs['n_candidates'] = args.n_candidates
    if args.n_reviewers:
        kwargs['n_reviewers'] = args.n_reviewers  
    if args.max_retries:
        kwargs['max_retries'] = args.max_retries
        
    orchestrator = create_sync_orchestrator(**kwargs)
    
    for bug in cases:
        print(f"\n--- SYNC –∫–µ–π—Å {bug['id']}: {bug['description']} ---")
        correlation_id = f"sync-case{bug['id']}-{int(time.time()*1000) % 10000}"
        result = orchestrator.run(bug["code"], bug["id"], correlation_id)
        analytics.add_result(result)
        
        # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        status_emoji = "‚úÖ" if result["status"] == "success" else "‚ùå"
        print(f"{status_emoji} –°—Ç–∞—Ç—É—Å: {result['status']}")
        if "metrics" in result:
            metrics = result["metrics"]
            print(f"   –í—Ä–µ–º—è: {metrics['execution_time_seconds']} —Å–µ–∫")
            print(f"   –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {metrics['total_candidates_generated']}")
            print(f"   –†–µ—Ç—Ä–∞–µ–≤: {metrics['retries_used']}")

async def run_async_approach(cases: List[Dict[str, Any]], seed: int, parallel: bool, analytics: OverallAnalytics, args):
    """–ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞."""
    mode_text = "–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ú" if parallel else "–ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–ú"
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –ê–°–ò–ù–•–†–û–ù–ù–û–ì–û –ø–æ–¥—Ö–æ–¥–∞ –≤ {mode_text} —Ä–µ–∂–∏–º–µ (seed={seed})")
    print("-" * 50)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
    kwargs = {'seed': seed}
    if args.n_reviewers:
        kwargs['n_reviewers'] = args.n_reviewers
    if args.max_retries:
        kwargs['max_retries'] = args.max_retries
        
    coordinator, agents, metrics = create_async_system(**kwargs)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤
    agent_tasks = [asyncio.create_task(agent.run()) for agent in agents]
    
    try:
        if parallel:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —Å–µ–º–∞—Ñ–æ—Ä–æ–º
            semaphore = asyncio.Semaphore(3)
            
            async def process_case_parallel(idx: int, bug: Dict[str, Any]):
                async with semaphore:
                    print(f"\n>>> [START] async –∫–µ–π—Å {bug['id']}: {bug['description']}")
                    correlation_id = make_cid(idx) 
                    result = await coordinator.run_case(bug["code"], bug["id"], correlation_id)
                    analytics.add_result(result)
                    
                    status_emoji = "‚úÖ" if result["status"] == "success" else "‚ùå" if result["status"] == "failed" else "‚è∞"
                    print(f"{status_emoji} [DONE] async –∫–µ–π—Å {bug['id']}: {result['status']}")
                    
                    if "metrics" in result:
                        m = result["metrics"]
                        print(f"    –í—Ä–µ–º—è: {m['execution_time_seconds']} —Å–µ–∫, –°–æ–æ–±—â–µ–Ω–∏–π: {m['messages_sent']}")
            
            await asyncio.gather(*[process_case_parallel(i, bug) for i, bug in enumerate(cases, 1)])
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            for i, bug in enumerate(cases, 1):
                print(f"\n--- ASYNC –∫–µ–π—Å {bug['id']}: {bug['description']} ---")
                correlation_id = make_cid(i)
                result = await coordinator.run_case(bug["code"], bug["id"], correlation_id)
                analytics.add_result(result)
                
                status_emoji = "‚úÖ" if result["status"] == "success" else "‚ùå" if result["status"] == "failed" else "‚è∞"
                print(f"{status_emoji} –°—Ç–∞—Ç—É—Å: {result['status']}")
                if "metrics" in result:
                    m = result["metrics"]
                    print(f"   –í—Ä–µ–º—è: {m['execution_time_seconds']} —Å–µ–∫")
                    print(f"   –°–æ–æ–±—â–µ–Ω–∏–π: {m['messages_sent']}/{m['messages_received']}")
                    print(f"   –¢–∞–π–º–∞—É—Ç—ã: {m['timeouts_occurred']}")
    finally:
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤
        for task in agent_tasks:
            task.cancel()
        await asyncio.gather(*agent_tasks, return_exceptions=True)

# ----------------------------- MAIN ---------------------------------

def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(description="MAS Demo: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤")
    parser.add_argument("--approach", choices=["sync", "async", "both"], default="both", 
                       help="–ö–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –∑–∞–ø—É—Å—Ç–∏—Ç—å: sync, async –∏–ª–∏ both")
    parser.add_argument("--parallel", action="store_true", 
                       help="–î–ª—è async: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–µ–π—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ")
    parser.add_argument("--seed", type=int, default=42, 
                       help="Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--verbose", action="store_true", 
                       help="–ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏")
    parser.add_argument("--cases", type=int, nargs='+', 
                       help="–ù–æ–º–µ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–µ–π—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: --cases 1 3 5)")
    parser.add_argument("--save-results", type=str, 
                       help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª")
    parser.add_argument("--use-openai", action="store_true", 
                       help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π OpenAI API –≤–º–µ—Å—Ç–æ –∏–º–∏—Ç–∞—Ü–∏–∏")
    parser.add_argument("--openai-model", type=str, default="gpt-4", 
                       help="–ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: gpt-4)")
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–∫–µ–π–ª–∏–Ω–≥–∞
    parser.add_argument("--n-candidates", type=int, 
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    parser.add_argument("--n-reviewers", type=int, 
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–≤—å—é–µ—Ä–æ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    parser.add_argument("--max-retries", type=int, 
                       help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—Ç—Ä–∞–µ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    return parser.parse_args()

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    args = parse_args()
    setup_logging(args.verbose)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å LLM
    if args.use_openai:
        if not is_openai_available():
            print("‚ùå OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt")
            print("   2. –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª .env —Å OPENAI_API_KEY")
            print("   3. API –∫–ª—é—á –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π")
            print("\nüîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Ä–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏...")
            args.use_openai = False
        else:
            print(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π OpenAI API (–º–æ–¥–µ–ª—å: {args.openai_model})")
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
            import os
            os.environ['OPENAI_MODEL'] = args.openai_model
            
            # –ó–∞–º–µ–Ω—è–µ–º –∏–º–ø–æ—Ä—Ç—ã LLM —Ñ—É–Ω–∫—Ü–∏–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ
            import approach1_sync
            import approach2_async
            from real_llm import llm_find_issues_wrapper, llm_suggest_fixes_wrapper, llm_review_fix_wrapper
            
            # Monkey patching –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ API
            approach1_sync.llm_find_issues = llm_find_issues_wrapper
            approach1_sync.llm_suggest_fixes = llm_suggest_fixes_wrapper  
            approach1_sync.llm_review_fix = llm_review_fix_wrapper
            approach2_async.llm_find_issues = llm_find_issues_wrapper
            approach2_async.llm_suggest_fixes = llm_suggest_fixes_wrapper
            approach2_async.llm_review_fix = llm_review_fix_wrapper
    else:
        print("üé≠ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏ LLM")
    
    # –í—ã–±–∏—Ä–∞–µ–º –∫–µ–π—Å—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if args.cases:
        cases = [case for case in BUG_CASES if case["id"] in args.cases]
        print(f"–í—ã–±—Ä–∞–Ω—ã –∫–µ–π—Å—ã: {[c['id'] for c in cases]}")
    else:
        cases = BUG_CASES
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ {len(cases)} –∫–µ–π—Å–æ–≤")
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ OpenAI
    if args.use_openai:
        print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–π OpenAI API!")
        print(f"   –ú–æ–¥–µ–ª—å: {args.openai_model}")
        print(f"   –ö–µ–π—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(cases)}")
        print(f"   –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ~${len(cases) * 0.01:.3f}")
        
        if len(cases) > 3:
            response = input("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ")
            if response.lower() not in ['y', 'yes', '–¥–∞']:
                print("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return
    
    analytics = OverallAnalytics()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ —Ä–∞–±–æ—Ç—ã –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É
    analytics.llm_mode = "openai" if args.use_openai else "simulation"
    analytics.openai_model = args.openai_model if args.use_openai else None
    
    # –ó–∞–ø—É—Å–∫ –ø–æ–¥—Ö–æ–¥–æ–≤
    if args.approach in ["sync", "both"]:
        await run_sync_approach(cases, args.seed, analytics, args)
    
    if args.approach in ["async", "both"]:
        await run_async_approach(cases, args.seed, args.parallel, analytics, args)
    
    # –í—ã–≤–æ–¥ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    analytics.print_summary()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if args.save_results:
        summary = analytics.generate_summary()
        summary["detailed_results"] = analytics.results
        summary["configuration"] = {
            "use_openai": args.use_openai,
            "openai_model": args.openai_model if args.use_openai else None,
            "seed": args.seed,
            "approach": args.approach,
            "parallel": args.parallel
        }
        
        with open(args.save_results, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.save_results}")

if __name__ == "__main__":
    asyncio.run(main())
